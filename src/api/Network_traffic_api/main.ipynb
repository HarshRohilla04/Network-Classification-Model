{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2168a80-2e6a-48e3-aa1a-100ad8b3497b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56b06398-af67-42dc-9149-201fe7b2b97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and encoder loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "# ----------------------------\n",
    "# 1. INITIALIZE APP & LOAD MODELS\n",
    "# ----------------------------\n",
    "# This runs once when the API starts\n",
    "app = FastAPI(title=\"Network Traffic Classifier API\", version=\"1.0\")\n",
    "\n",
    "# Load the trained model and the one-hot encoder\n",
    "model = joblib.load(\"Models/lightgbm_packet_model.pkl\")\n",
    "ohe = joblib.load(\"Models/ohe_protocol.pkl\")\n",
    "print(\"Model and encoder loaded successfully.\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. DEFINE DATA INPUT MODEL\n",
    "# ----------------------------\n",
    "# This defines what a single packet's data should look like for an API request.\n",
    "class Packet(BaseModel):\n",
    "    Time: float\n",
    "    Source: str\n",
    "    Destination: str\n",
    "    Protocol: str\n",
    "    Length: int\n",
    "    Info: str\n",
    "\n",
    "class PacketList(BaseModel):\n",
    "    packets: List[Packet]\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 3. FEATURE ENGINEERING FUNCTION\n",
    "# ----------------------------\n",
    "# This function replicates the feature engineering from your notebook.\n",
    "def create_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Takes a raw packet dataframe and returns a dataframe with engineered features.\"\"\"\n",
    "    \n",
    "    # Ensure Info is a string\n",
    "    df['Info'] = df['Info'].astype(str)\n",
    "\n",
    "    # Patterns and keywords from the notebook\n",
    "    port_pattern = re.compile(r'(\\d{1,5})\\s*>\\s*(\\d{1,5})')\n",
    "    flags = ['SYN', 'ACK', 'PSH', 'RST', 'FIN', 'URG', 'ECE', 'CWR']\n",
    "    keywords = ['http', 'tls', 'quic', 'dns', 'get', 'post', 'rtp', 'rtcp', 'rtsp', 'ssl', 'video', 'audio', 'application data']\n",
    "\n",
    "    # Basic text-derived features\n",
    "    df['info_len'] = df['Info'].apply(len)\n",
    "    df['digits_in_info'] = df['Info'].apply(lambda s: sum(ch.isdigit() for ch in s))\n",
    "\n",
    "    # Extract ports\n",
    "    ports = df['Info'].apply(lambda s: port_pattern.search(s))\n",
    "    df['src_port'] = ports.apply(lambda m: int(m.group(1)) if m else np.nan)\n",
    "    df['dst_port'] = ports.apply(lambda m: int(m.group(2)) if m else np.nan)\n",
    "\n",
    "    # Flags presence\n",
    "    for f in flags:\n",
    "        df['flag_' + f] = df['Info'].apply(lambda s: 1 if f in s else 0)\n",
    "\n",
    "    # Keywords indicators\n",
    "    for k in keywords:\n",
    "        col = 'has_' + k.replace(' ', '_')\n",
    "        df[col] = df['Info'].str.lower().str.contains(k).fillna(False).astype(int)\n",
    "\n",
    "    # Time delta (crucial for time-series features)\n",
    "    df = df.sort_values('Time').reset_index(drop=True)\n",
    "    df['delta_time'] = df['Time'].diff().fillna(0.0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# 4. PREDICTION ENDPOINT\n",
    "# ----------------------------\n",
    "# This is the main endpoint that will receive data and return predictions.\n",
    "@app.post(\"/predict\")\n",
    "def predict_traffic(data: PacketList):\n",
    "    \"\"\"\n",
    "    Predicts the traffic type for a list of packets.\n",
    "    \n",
    "    - **packets**: A list of packet data objects.\n",
    "    \"\"\"\n",
    "    # 1. Convert incoming JSON data to a Pandas DataFrame\n",
    "    input_df = pd.DataFrame([p.dict() for p in data.packets])\n",
    "\n",
    "    # 2. Create features using the same logic as in the notebook\n",
    "    features_df = create_features(input_df)\n",
    "\n",
    "    # 3. Prepare the feature matrix for the model (must match training)\n",
    "    candidate_features = [\n",
    "        'Length', 'info_len', 'digits_in_info', 'delta_time', 'src_port', 'dst_port'\n",
    "    ] + [f'flag_{f}' for f in flags] + ['has_' + k.replace(' ', '_') for k in keywords] + ['Protocol']\n",
    "    \n",
    "    X_df = features_df[[c for c in candidate_features if c in features_df.columns]].copy()\n",
    "\n",
    "    X_df['src_port'] = X_df['src_port'].fillna(-T1).astype(int)\n",
    "    X_df['dst_port'] = X_df['dst_port'].fillna(-1).astype(int)\n",
    "    if 'Length' in X_df:\n",
    "        X_df['Length'] = X_df['Length'].fillna(X_df['Length'].median())\n",
    "\n",
    "    # 4. Apply the OneHotEncoder and combine features robustly\n",
    "    cat_cols = [c for c in ['Protocol'] if c in X_df.columns]\n",
    "    num_cols = [c for c in X_df.columns if c not in cat_cols]\n",
    "\n",
    "    # Get the numeric data and reset its index\n",
    "    X_num = X_df[num_cols].astype(float).fillna(0.0).reset_index(drop=True)\n",
    "    \n",
    "    # Handle the categorical data\n",
    "    if cat_cols:\n",
    "        X_cat = X_df[cat_cols].fillna('missing').astype(str)\n",
    "        P_sparse = ohe.transform(X_cat)\n",
    "        \n",
    "        # Robustly get feature names for different scikit-learn versions\n",
    "        try:\n",
    "            P_cols = list(ohe.get_feature_names_out(cat_cols))\n",
    "        except AttributeError:\n",
    "            P_cols = list(ohe.get_feature_names(cat_cols))\n",
    "\n",
    "        # Create DataFrame from encoded data and reset its index\n",
    "        P_df = pd.DataFrame(P_sparse.toarray(), columns=P_cols).reset_index(drop=True)\n",
    "        \n",
    "        # Concatenate numeric and encoded dataframes\n",
    "        X_pre = pd.concat([X_num, P_df], axis=1)\n",
    "    else:\n",
    "        X_pre = X_num.copy()\n",
    "\n",
    "    # Sanitize column names for LightGBM\n",
    "    X_pre.columns = [re.sub(r'[^0-9a-zA-Z_]', '_', str(c)) for c in X_pre.columns]\n",
    "\n",
    "    # 5. Make predictions\n",
    "    predictions = model.predict(X_pre)\n",
    "\n",
    "    # 6. Return the results\n",
    "    input_df['predicted_label'] = predictions\n",
    "    \n",
    "    return {\"predictions\": input_df.to_dict(orient=\"records\")}\n",
    "\n",
    "# A simple root endpoint to check if the API is running\n",
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "    return {\"message\": \"Welcome to the Network Traffic Classifier API. Go to /docs for details.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d257f048-4d2d-432b-bafd-4479f88429e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137cf660-3305-40df-9ccb-cc122913d89b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
